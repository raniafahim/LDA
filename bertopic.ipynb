{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b728cf-e2d9-47b1-96d3-1ff5d143e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -q bertopic spacy polars datasets hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ccdfca-6dd8-4865-a73c-234130ecf8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -q https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656026cc-3086-4497-a74a-e22da77315e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/.venv/lib/python3.12/site-packages/hdbscan/plots.py:448: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  axis.set_ylabel('$\\lambda$ value')\n",
      "/home/onyxia/work/.venv/lib/python3.12/site-packages/hdbscan/robust_single_linkage_.py:154: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  \"\"\"Perform robust single linkage clustering from a vector array\n",
      "/home/onyxia/work/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance, PartOfSpeech\n",
    "from hdbscan import HDBSCAN\n",
    "from scipy.cluster import hierarchy as sch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "from umap import UMAP\n",
    "import polars as pl\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecab0f10-cf21-4f02-8426-e00ef4d823d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4651fb00-9f7f-4607-95b3-ad4779f270fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(docs):\n",
    "    cleaned = []\n",
    "    for doc in nlp.pipe(docs, batch_size=20):\n",
    "        tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "        cleaned.append(' '.join(tokens))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866cae73-656c-44a9-b29b-84ad0dfca928",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICTIONNARY =  ['accord','entreprise', 'preambule', 'sommaire',  'code', 'syndical', 'responsable', 'representant', \n",
    "                'present', 'ca', 'organisation', 'preambule', 'peut', 'etre', 'contrat','travail', 'ressources','humaines', 'mise',\n",
    "                'ainsi', 'et', 'ou', 'alors','collaborateur', 'ci', 'apres', 'party', 'signataire', 'tout', 'etat', 'cause', 'societe', \n",
    "                'notamment','article','activite', 'cette', 'donc', 'si', 'sous', 'disposition', 'convention', 'collective', 'dans', 'a', 'cadre',\n",
    "                'signataire', 'partie', 'parties', 'entre', 'doit', 'mme', 'mr', 'madame', 'monsieur'\n",
    "               ]\n",
    "\n",
    "DICTIONNARY_STEM = ['part', 'signatair', 'organis', 'syndical', \n",
    "                    'dont', 'sieg', 'social', 'conseil', 'prud', 'homm', \n",
    "                   'vi', 'professionnel', 'disposit', 'legal', 'conventionnel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e0c94a-9bf1-4d0a-9ebb-4e93ff8c32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize(text):\n",
    "    return text.lower().strip()\n",
    "\n",
    "def split_text_by_sentences(text, flagged_sentences):\n",
    "    split_texts = []\n",
    "    positions = []\n",
    "\n",
    "    normalized_text = normalize(text)\n",
    "\n",
    "    # On garde un mapping (titre original, position) pour préserver les titres initiaux\n",
    "    for sentence in flagged_sentences:\n",
    "        norm_sentence = normalize(sentence)\n",
    "        pos = normalized_text.find(norm_sentence)\n",
    "        if pos != -1:\n",
    "            # On retrouve la position réelle dans le texte original\n",
    "            real_pos = text.lower().find(sentence.lower())\n",
    "            if real_pos != -1:\n",
    "                positions.append(real_pos)\n",
    "\n",
    "    # Si aucune position trouvée, retourner le texte complet\n",
    "    if not positions:\n",
    "        return [text]\n",
    "\n",
    "    positions = sorted(set(positions))\n",
    "    positions.insert(0, 0)\n",
    "    positions.append(len(text))\n",
    "\n",
    "    for i in range(len(positions) - 1):\n",
    "        start = positions[i]\n",
    "        end = positions[i + 1]\n",
    "        split_texts.append(text[start:end].strip())\n",
    "\n",
    "    return split_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789cfbb5-3204-412f-8fa9-c1c06bef4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_with_titles(text, summary_titles):\n",
    "    chunks = split_text_by_sentences(text, summary_titles)\n",
    "    result = {}\n",
    "    for title in summary_titles:\n",
    "        for chunk in chunks:\n",
    "            if normalize(title) in normalize(chunk[:len(title)+30]):\n",
    "                result[title] = chunk.strip()\n",
    "                break\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fed77fd-7c52-4312-ab55-2b979f4f3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "sommaire_hs = pd.read_parquet(\"data/echantillon_1000_hs_accords_TOC.parquet\")\n",
    "df_hs = pd.read_parquet(\"data/echantillon_1000_hs_accords.parquet\")\n",
    "df_hs = df_hs.set_index(\"numdossier_new\")\n",
    "df_hs = df_hs.merge(sommaire_hs,how=\"inner\",left_index=True,right_index=True)\n",
    "df_hs = df_hs.rename(columns={\"extracted_summary\":\"summary\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71e5407-d0ee-4ad0-b57a-eb045f7675ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs[\"section_dict\"] = df_hs.apply(\n",
    "    lambda row: split_text_with_titles(row[\"accorddocx\"], row[\"summary\"]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83080475-ddc9-4ee3-ab90-31268c509b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_chunks(section_dict):\n",
    "    chunks = list(section_dict.values())\n",
    "    return [chunk.strip() for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "845c6ec4-de10-4041-a241-adc376ac6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_chunks_filtered(section_dict, skip_titles=[\"préambule\", \"annexe\"], seuil_sim=0.85):\n",
    "    skip_titles_norm = [normalize(t) for t in skip_titles]\n",
    "\n",
    "    # supprimer le préambule et avant \n",
    "    titles = list(section_dict.keys())\n",
    "    preamble_idx = next((i for i, t in enumerate(titles) if \"préambule\" in normalize(t)), -1)\n",
    "    if preamble_idx != -1:\n",
    "        titles = titles[preamble_idx + 1:]\n",
    "\n",
    "    # garder les titres valides uniquement\n",
    "    valid_titles = [\n",
    "        t for t in titles if all(skip_kw not in normalize(t) for skip_kw in skip_titles_norm)\n",
    "    ]\n",
    "    candidate_dict = {t: section_dict[t] for t in valid_titles}\n",
    "\n",
    "    # filtrer par similarité des titres\n",
    "    return filtre_chunks_par_titre(candidate_dict, phrases_non_metier, seuil=seuil_sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4b733b-96a0-46d9-9bf3-411145816e9d",
   "metadata": {},
   "source": [
    "# Sans filtrer les chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f6f287-5e05-4e9e-a006-df80af03c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs[\"lda_documents\"] = df_hs[\"section_dict\"].apply(get_all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93557c93-285e-4d3f-9302-728b566ff2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks_hs = [chunk for doc_chunks in df_hs[\"lda_documents\"] for chunk in doc_chunks]\n",
    "all_docs_cleaned = preprocess(all_chunks_hs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01518c-58f2-49fb-addb-8e3a8e4da585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embeddings --> étape trop longue sans gpu \n",
    "start = time.time()\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\",device='cuda')  \n",
    "embeddings = embedding_model.encode(all_docs_cleaned, show_progress_bar=True)\n",
    "print(f\"[1] Embedding en {time.time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ae8c1-79e0-426e-9bb9-2843755d70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACP --> plus rapide \n",
    "start = time.time()\n",
    "pca_model = PCA(n_components=5)\n",
    "pca_embeddings = pca_model.fit_transform(embeddings)\n",
    "print(f\"[PCA] en {time.time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717dc42-868e-4097-b9bb-cb516c2f45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Réduction UMAP --> trop long besoin de trouver une version avec gpu \n",
    "#start = time.time()\n",
    "#umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "#umap_embeddings = umap_model.fit_transform(embeddings)\n",
    "#print(f\"[2] UMAP en {time.time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c4d9ef-5466-4a37-b87f-bd750bf077ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering \n",
    "start = time.time()\n",
    "hdbscan_model =  HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "clusters = hdbscan_model.fit_predict(pca_embeddings)\n",
    "print(f\"[3] HDBSCAN en {time.time() - start:.2f}s\")\n",
    "print(f\"[3] Nombre de clusters trouvés : {len(np.unique(clusters))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405125d8-f953-4e07-96a8-554ecdeddd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "topic_model = BERTopic(\n",
    "    language=\"french\",\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=pca_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    verbose=True\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(all_docs_cleaned, embeddings=embeddings)\n",
    "print(f\"[4] BERTopic final en {time.time() - start:.2f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745311ca-11d0-435b-848c-b8e01af3a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25cf99d-5808-46c0-a93e-67454069fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9238caa-5a3d-4a05-aae1-1322f197d90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from random import sample\n",
    "#sample_docs = sample(all_docs_cleaned, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0149d3-129f-4f6d-b882-bccb55b7fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model_no_filter = BERTopic(language=\"french\")\n",
    "#topics_no_filter, probs_no_filter = topic_model_no_filter.fit_transform(sample_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0acfe0-d8e0-4168-8a31-de68f146a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bertopic import BERTopic\n",
    "#topic_model_no_filter = BERTopic(language=\"french\")\n",
    "#topic_no_filter, probs_no_filter = topic_model_no_filter.fit_transform(all_docs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cded9b-2e03-435a-bc64-d79ca58a4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e722759-1ef0-438a-bb87-810a58d7d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e6d3f-9a6d-46c4-84f8-2e4cf36eaccb",
   "metadata": {},
   "source": [
    "# En filtrant les chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269f50f-4b5e-4337-b26c-caa49859b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_hs[\"lda_documents\"] = df_hs[\"section_dict\"].apply(get_valid_chunks_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffb133-58cd-4f13-9615-339ca6fba633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_chunks_hs = [chunk for doc_chunks in df_hs[\"lda_documents\"] for chunk in doc_chunks]\n",
    "#filtered_docs_cleaned = preprocess(all_chunks_hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2a5ba-004e-4e90-a4fa-58784b93ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bertopic import BERTopic\n",
    "#topic_model_filter = BERTopic(language=\"french\")\n",
    "#topic_model_filter, probs_no_filter = topic_model_no_filter.fit_transform(all_docs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e052ce-50a4-42ff-a265-100334e35986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84ad42-d652-4cdb-84be-4c473e629a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f8bdd6-b82a-4189-b2c5-c2cd11ea7535",
   "metadata": {},
   "source": [
    "# BERTopic (KeyBERTInspired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968bd331-5a76-464f-a025-fbf22a44607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#representation_model = KeyBERTInspired()\n",
    "\n",
    "#topic_model = BERTopic(representation_model=representation_model,language=\"french\")\n",
    "#topics, probs = topic_model.fit_transform(docs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3130a-66dd-4880-9a17-db4707e88dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.get_topic_info()topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47ab6f-201c-415c-9f13-09701a38cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb890422-1c29-481e-86a9-b7844d9268d7",
   "metadata": {},
   "source": [
    "# BERTopic (MMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c071c-ff90-4bfb-8dc0-b88b2d83e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#representation_model = MaximalMarginalRelevance(diversity=0.3)\n",
    "\n",
    "#topic_model = BERTopic(representation_model=representation_model,language=\"french\")\n",
    "#topics, probs = topic_model.fit_transform(docs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9917cc-d81e-4ba9-8ccd-9264923f62a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d201d78-22d4-40c5-b484-2b2387d608a4",
   "metadata": {},
   "source": [
    " # Hierarchical topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a8ab4-1904-4337-b461-29b75be89de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hierarchical_topics = topic_model.hierarchical_topics(docs_cleaned)\n",
    "#hierarchical_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ece152-ffdc-4a07-a968-e39490faadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linkage_function = lambda x: sch.linkage(x, 'single', optimal_ordering=True)\n",
    "#hierarchical_topics = topic_model.hierarchical_topics(docs_cleaned, linkage_function=linkage_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23f112-7b20-42a8-9e69-cd86abac6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv-bt)",
   "language": "python",
   "name": "my-uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
